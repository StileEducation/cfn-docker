#!/usr/bin/env python

import os
import logging
import argparse
import boto.utils
import docker
import subprocess
import json
import urllib2
import socket
from tsort import topological_sort
from threading import Thread
import sys

CONFIG_DIR = '/var/lib/cfn-docker'
METADATA_FILE = CONFIG_DIR + '/metadata.json'
logger = logging.getLogger('cfn-docker')

# Use API version provided by the server
docker_client = docker.Client(version='auto')

def main():
    logging.basicConfig(level=logging.INFO)

    if not os.path.isdir(CONFIG_DIR):
        os.mkdir(CONFIG_DIR)

    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers()

    fetch_parser = subparsers.add_parser('fetch', help='Fetch configuration from CloudFormation metadata')
    fetch_parser.set_defaults(func=fetch)
    fetch_parser.add_argument('--stack-name', required=True, help="CloudFormation stack name")
    fetch_parser.add_argument('--resource-name', required=True, help="CloudFormation resource in stack")

    up_parser = subparsers.add_parser('up', help='Ensure all containers in the fetched CloudFormation metadata are running')
    up_parser.add_argument('--force-pull', '-f', action='store_true', help="Force docker to pull from repo, even if it already has a local copy.")
    up_parser.add_argument('--container', '-c', help="Only a specific container, rather than all known container types")
    up_parser.add_argument('--restart', '-r', action='store_true', help="Force restart container(s)")
    up_parser.set_defaults(func=up)

    run_parser = subparsers.add_parser('run', help='Ensure all containers in the fetched CloudFormation metadata are running')
    run_parser.add_argument('--container', '-c', help="Container type to execute command in.")
    run_parser.add_argument('--command', help="Command to pass to the container")
    run_parser.set_defaults(func=run)

    status_parser = subparsers.add_parser('status', help='Return status of containers')
    status_parser.set_defaults(func=status)

    # Parse arguments and run selected subcommand.
    # Subcommands register their main function in argparse as a default for `func`.
    args = parser.parse_args()
    args.func(args)

def fetch(args):
    instance_metadata = boto.utils.get_instance_metadata()
    region = instance_metadata['placement']['availability-zone'][:-1]   # TODO: feels hacky

    # Call out to cfn-get-metadata instead of using boto because it uses special CFN authentication
    # that requires no credentials.
    out, err = subprocess.Popen(['/opt/aws/bin/cfn-get-metadata',
        '--region', region,
        '-s', args.stack_name,
        '-r', args.resource_name,
        '-k', 'Docker'], stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()
    # TODO: check exit code

    # Parse and write out metdata
    docker_metadata = json.loads(out)
    # TODO: validate schema
    with open(METADATA_FILE, 'w') as f:
        f.write(json.dumps(docker_metadata, indent=4))

# Check that all containers are running.
def status(args):
    stopped_count = 0
    with open(METADATA_FILE, 'r') as f:
        docker_metadata = json.load(f)

    for container_name in docker_metadata.get('containers', {}):
        if container_exists(container_name) and container_running(container_name):
            print container_name + '\t RUNNING'
        else:
            print container_name + '\t STOPPED'
            stopped_count += 1

    if stopped_count > 0:
        sys.exit(1)


def up(args):
    with open(METADATA_FILE, 'r') as f:
        docker_metadata = json.load(f)

    # Look for special environment variable functions
    for container in docker_metadata.get('containers', {}).values():

        for key, value in container.get('environment', {}).items():
            if type(value) is dict and len(value) == 1:
                container['environment'][key] = env_function(value)

        # There are also environemnts in the prestarts, so look there too.
        for beforeStart in container.get('beforeStart' , []):

            for key, value in beforeStart.get('environment', {}).items():
                if type(value) is dict and len(value) == 1:
                    beforeStart['environment'][key] = env_function(value)

    if args.container:
        config = docker_metadata['containers'].get(args.container)
        if config:
            run_single(args.container, config, args.restart)
        else:
            logger.info('Could not find container type %s' % (args.container))

    else:
        # Pull all the containers
        for name, config in docker_metadata['containers'].iteritems():
            ensure_image(config['image'])

        for name, config in dependency_sort(docker_metadata['containers']):
            run_single(name, config, restart=args.restart, forcePull=args.force_pull)

def run(args):
    with open(METADATA_FILE, 'r') as f:
        docker_metadata = json.load(f)

    config = docker_metadata['containers'].get(args.container)
    if config:
        ensure_image(config['image'])

        # Substitute environment variables
        for key, value in config.get('environment', {}).items():
            if type(value) is dict and len(value) == 1:
                config['environment'][key] = env_function(value)

        command = ['/usr/bin/docker', 'run', '-i']
        # Allocate a TTY when being used on stdin (which will be the user's expectation)
        # Don't do this otherwise, because we call this over an SSH pipe from the new
        # deploy-server-2 to run stuff
        if sys.stdout.isatty():
            command += ['-t']

        for k, v in config.get('environment', {}).iteritems():
            command.append('-e')
            command.append("%s=%s" % (k ,v))

        command.append(config['image'])
        command.append(args.command)

        logger.info('Launching %s with command %s' % (args.container, args.command))
        subprocess.call(command)
    else:
        logger.info('Could not find container type %s' % (args.container))


def run_single(name, config, restart=False, forcePull=False):
    ensure_image(config['image'])

    #
    if forcePull:
        docker_client.pull(config['image'])
        # If there is already a container, remove it so it gets recreated below.
        if container_exists(name):
            if container_running(name):
                docker_client.kill(name)
            docker_client.remove_container(name)

    if container_exists(name) and configuration_changed(name, config):
        logger.info('Configuration has changed. Removing container %s' % (name))
        if container_running(name):
            docker_client.kill(name)
        docker_client.remove_container(name)


    if not container_exists(name):

        # Run any commands that need to happen before the container starts
        for beforeStart in config.get('beforeStart', []):
            logger.info('Running %s beforeStart for command %s' % (name, beforeStart.get('command', "")))

            # The beforeStart environment is also has the normal container environment
            beforeStartEnvironment = dict(config['environment'].items() + beforeStart['environment'].items())
            beforeStartEnvironment['HOST_HOSTNAME'] = socket.gethostname()
            container_name = "%s-pre" % (name)

            docker_client.create_container(config['image'], name=container_name, environment=beforeStartEnvironment, command=beforeStart.get('command', None), hostname=socket.gethostname())
            try:
                docker_client.start(container_name, binds=config.get('volumes', None), port_bindings=config.get('ports', None), links=None)
                exit_code = docker_client.wait(container_name)
                logger.info(docker_client.logs(container_name))
            finally:
                docker_client.remove_container(container_name)

        logger.info('Creating container %s' % (name))

        # Add instance's AZ to environment as DATACENTER
        environment = config.get('environment', {})
        instance_metadata = boto.utils.get_instance_metadata()
        az = instance_metadata['placement']['availability-zone']
        environment['DATACENTER'] = az[-1:] # AZ letter only (a, b, etc). Most shells don't like hyphens in environment variable names.
        # Plumb through the host's hostname into and env var
        # Although this is currently also being pushed through as HOSTNAME in the container,
        # we want to stop doing that because it shadows the container id (which docker sets
        # to HOSTNAME by default)
        environment['HOST_HOSTNAME'] = socket.gethostname()

        # The SYSLOG_ADDR_HOST needs to be the address of the host.
        # THat is either localhost if the container is running in host network mode, or the address of the host
        # on the bridge in bridge mode.
        net_mode = config.get('net', 'bridge')
        if net_mode == 'host':
            environment['SYSLOG_ADDR_HOST'] = '127.0.0.1'
            environment['SYSLOG_ADDR_PORT'] = '514'
        elif net_mode == 'bridge':
            environment['SYSLOG_ADDR_HOST'] = '172.17.0.1' # Hardcoded inside base image
            environment['SYSLOG_ADDR_PORT'] = '514'
        else:
            # ?? What networking mode is this? I guess we'll omit the syslog configuration until someone comes in
            # and adds something sensible here.
            pass

        # By default, we are setting the hostname in the container to the hostname of the host
        # This adds an entry like "172.x.x.x host.hostname.au.s522.net" in the /etc/hosts file
        # This means that processes inside the container cannot actually connect to the real "host.hostname.au.s522.net"
        # This is Really Annoying for the mongo MMS monitor, which gets the hostnames to connect to mongo from the
        # cloud service - so the FQDN needs to work.
        hostname_config = config.get('hostname', None)
        if hostname_config is None:
            container_hostname = socket.gethostname()
        elif isinstance(hostname_config, dict):
            if hostname_config.get('cfn-docker::default-hostname', False):
                container_hostname = None
            else:
                container_hostname = socket.gethostname()
        elif isinstance(hostname_config, basestring):
            container_hostname = hostname_config
        else:
            raise Exception('unknown hostname format %s' % hostname_config)

        # Cloudformation turns our bools into strings...
        privileged = config.get('privileged', False)
        if not isinstance(privileged, bool):
            privileged = (privileged.lower() == 'true')

        # and also our ints into strings
        for limit in config.get('ulimits', []):
            for k in ('soft', 'hard', 'Soft', 'Hard'):
                if k in limit:
                    limit[k] = int(limit[k])

        cpu_shares = config.get('cpu_shares', None)
        if not cpu_shares is None:
            cpu_shares = int(cpu_shares)

        ports = None
        if 'ports' in config:
            # By default, the exposedPorts will be what was set in EXPOSE in the dockerfile
            # If we are forwarding ports that were not exposed, this won't work.
            # Hack by setting the exposed ports equal to the forwarded ports
            ports = config['ports'].keys()

        docker_client.create_container(
            config['image'],
            name=name,
            environment=environment,
            command=config.get('command', None),
            hostname=container_hostname,
            ports=ports,
            host_config=docker_client.create_host_config(
                binds=config.get('volumes', None),
                port_bindings=config.get('ports', None),
                links=config.get('links', None),
                restart_policy={ "Name": "always" },
                network_mode=config.get('net', 'bridge'),
                privileged=privileged,
                ulimits=config.get('ulimits', None),
                cpu_shares=cpu_shares,
                ipc_mode=config.get('ipc', None)
            )
        )

    if not container_running(name):
        logger.info('Starting container %s' % (name))
        docker_client.start(name)
    else: #If the container is actually running
        if restart:
            logger.info('Restarting container %s' % (name))
            docker_client.restart(name, timeout=30)

# Docker API utility functions
def container_exists(name):
    full_name = '/%s' % (name)
    return any(full_name in i['Names'] for i in docker_client.containers(all=True))

def image_exists(name):
    # TODO: append :latest if there is not tag
    return any(name in i['RepoTags'] for i in docker_client.images() if i.get('RepoTags', None) is not None)

def ensure_image(name):
    if not image_exists(name):
        logger.info('Pulling image %s' % (name))
        docker_client.pull(name)
        logger.info('Finished pulling image %s' % (name))

def configuration_changed(name, new_config):
    container = docker_client.inspect_container(name)

    # TODO: detect more interesting changes
    # container['Config']['Env']
    # container['HostConfig']['PortBindings']
    # volumes
    # links

    return any([
        container['Config']['Image'] != new_config['image']
    ])

def container_running(name):
    container = docker_client.inspect_container(name)
    return container['State']['Running']


# Environment variable functions
def env_function(value):
    fn = value.keys()[0]
    arg = value.values()[0]

    if fn == 'cfn-docker::url':
        return urllib2.urlopen(arg).read()
    else:
        raise Exception('Unknown function: %s' % (fn))

# Sort containers dict in dependency order using t-sort and return a list of (name, config) pairs
def dependency_sort(containers_dict):
    dependencies = []

    # Build dependency DAG for links
    for name, config in containers_dict.items():
        links = config.get('links', {}).keys()
        for link in links:
            dependencies.append((link, name))

    sorted_names = topological_sort(dependencies)

    # sorted_names only includes containers that had dependencies - add any that are missing
    missing_names = list(set(containers_dict.keys()) - set(sorted_names))
    sorted_names.extend(missing_names)

    ordered_configs = map(lambda k: containers_dict[k], sorted_names)

    return zip(sorted_names, ordered_configs)

if __name__ == "__main__":
    main()